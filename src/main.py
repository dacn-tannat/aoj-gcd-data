"""
Main script for processing raw data.

This script imports necessary functions from the services module and processes
the raw data stored in 'raw_data_c.json' when run as the main program.
"""

from services.data_services import *

if __name__ == '__main__':
    '''
    Usage:
    1. Crawl (if needed) and preprocess data from AOJ: 
        process_prepare_data()
        
    Result: 
        raw_data.json           Crawled data from AOJ, just read from this file if already crawled
                                11330 records
        preprocessed_data.json  Preprocess raw data
        literal_map_data.json   Mapping between distinct tokens to its encoded ID
    
    2. Split preprocessed data into train data and raw metrics data:
        process_split_data()
        
    Result:
        ac_data.json            Data only includes source code with status == 4 (accepted code)
        train_data.json         Data used to train the model
                                3501 records
        raw_metrics_data.json   (Unprocessed) data, used to run evaluation metrics
                                390 records

    3. Generate unprocessed data from accepted codes by prompting LLM
        process_generate_buggy_data()
        
    Result:
        raw_buggy_data.json     Unprocessed buggy data
                                each object contains judge_id (to map with the original source code) 
                                and its 5 buggy source codes which generated by LLM
    '''
    
    # # NEW FLOW
    # 1. Bỏ các fields không cần thiết đi
    # train_data = process_remove_fields(data=read_json_file('processed_train_data_delete.json'), fields=['raw_tokens', 'encoded_tokens'])
    # print(len(train_data))
    # save_json_file(data=train_data, file_name='train_data_2.json')
    
    # metrics_data = process_remove_fields(data=read_json_file('unprocessed_metrics_data.json'), fields=['raw_tokens', 'encoded_tokens'])
    # print(len(metrics_data))
    # save_json_file(data=metrics_data, file_name='metrics_data.json')
    
    # # 2. Process train_data -> processed_train_data.json, vocab_map_data.json và literal_map_data.json
    # processed_train_data = process_prepare_data('train_data.json')
    # print(len(processed_train_data))
    
    # test_handle_oov()
    
    # # 3. Process metrics_data -> processed_metrics_data.json, oov_tokens_metrics.json
    # processed_metrics_data, oov_tokens_metrics = process_metrics_data('metrics_data.json')
    # save_json_file(data=processed_metrics_data, file_name='processed_metrics_data.json')
    # save_json_file(data=oov_tokens_metrics, file_name='oov_tokens_metrics.json')
        
    # # 4. Process buggy_data -> processed_buggy_data.json, oov_tokens_buggy.json
    # processed_buggy_data, oov_tokens_buggy = process_metrics_data('buggy_data.json')
    # save_json_file(data=processed_buggy_data, file_name='processed_buggy_data.json')
    # save_json_file(data=oov_tokens_buggy, file_name='oov_tokens_buggy.json')
    
    # # 5. Label -> labeled_buggy_data.json
    # labeled_buggy_data = process_label_bug_positions()
    # print(len(labeled_buggy_data))
    
    # # 6. Merge -> final_metrics_data.json
    # final_metrics_data = process_merge_data()
    # save_json_file(data=final_metrics_data, file_name='final_metrics_data.json')

    # process_group_judge_ids_by_user_id()
    process_get_pairs()
    # process_similarity()
    # process_filter_pairs()